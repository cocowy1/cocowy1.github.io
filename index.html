<html>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <head>
    <title>Yun Wang</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://at.alicdn.com/t/font_1155135_oq1ut3zz63j.css">
    <link rel="stylesheet" type="text/css" href="css/style.css">
    <link rel="stylesheet" type="text/css" href="css/fonts.css">
</head>

<body>
	<div class="main-container">
    <!-------------------------------  Introduction -------------------------------------------->
    <div class="content-container font-hei">
      <div class="hflex-container" id="profile">
      <img src="images/yunwang.jpg">
      <div>
        <br>
        <b style="font-size:25px">&nbsp;Yun Wang (汪赟)</b>
        <br><br>
        <table>
          <tbody>
            <tr>
              <td>
                PhD Student @ CityU of HK
              </td>
            </tr>
            <tr>
              <td><br>Ph.D. from <a href="https://www.cityu.edu.hk/" target="_blank">City University of Hong Kong</a></td>
            </tr>
            <tr>
              <!-- <td width="60px"><b>Email</b></td> -->
              <td><br><i class="fa fa-envelope" style="color:black;font-size:22;"></i> yunwang9218@gmail.com</td>
            </tr>
        <tr>
          <td colspan="2">
            <!-- <br> -->
            <a href="https://github.com/cocowy1" target="_blank"><i class="fa fa-github" style="color:black;font-size:22;"></i>&nbsp;Github</a>
            <!-- <a href="https://www.zhihu.com/people/fly-cfchen/activities" target="_blank"><i class="iconfont icon-zhihu" style="color:black;"></i>&nbsp;Zhihu</a> -->
            <!-- <a href="files/resume-cfchen-en.pdf" target="_blank"><i class="iconfont icon-jianli" style="color:black;font-size:20;"></i>&nbsp;CV</a> -->
            <!-- <a href="https://www.linkedin.com/in/%E9%99%88-%E8%B6%85%E9%94%8B-aa96518b/" target="_blank"><i class="fa fa-linkedin-square" style="color:black;font-size:22;"></i>&nbsp;LinkedIn</a> -->
            <a href="https://scholar.google.com/citations?user=8fma3awAAAAJ&hl=en" target="_blank"><i class="iconfont icon-gscholar" style="color:black;font-size:20;"></i>&nbsp;Google Scholar</a>
          </td>
          </td>
        </tr>
          </tbody>
        </table>
        </div>
      </div>

    <!-------------------------------  About me -------------------------------------------->
		<!-- <div class="content-container"> -->
			<h2>Biography</h2>
			<p>
        I am currently pursuing my Ph.D. at the City University of Hong Kong (CityU), under the supervision of <a href="https://www.cs.cityu.edu.hk/~dapengwu/" target="_blank">Prof. 
 	Dapeng Oliver Wu</a>. 
        During my doctoral studies, I completed an internship at the Shenzhen Institute of Artificial Intelligence and Robotics for Society (AIRS), where I had the opportunity to work closely with <a href="https://junjh.github.io/" target="_blank">Prof. Junjie Hu</a>. 
       	Prior to this, I earned my M.E. degree from Sun Yat-sen University (SYSU) in 2023, under the supervision of <a href="https://www.yulanguo.cn/" target="_blank">Prof. 
 	Yulan Guo</a>. 

	<p>My research interests include 3D Computer Vision and Large Multimodal Models. Current research topics include:</p>
          <ul>
            <li>3D Vision about Depth</li>
	    <li>Stereo Matching</li>
            <li>Large Multimodal Model</li>
            <li>Video Understanding</li>
	</ul>
      
    
    <!-------------------------------  Education -------------------------------------------->
      <h2>News</h2>
      <!-- <ul> -->
      <div class="news">
        <ul class="news">
          <li>2025-06: Two papers were accepted to ICCV 2025.</li>
	  <li>2025-02: One paper was accepted to TIP.</li>
          <li>2024-12: One paper was accepted to AAAI 2025 (Oral).</li>
          <li>2024-10: One paper was accepted to TIP.</li>
          <li>2024-07: One paper was accepted to ECCV 2024.</li>
        </ul>
      </div>

      <!-------------------------------  Experience -------------------------------------------->
      <!-- <div class="content-container" display="flex"> -->
      <h2>Experience</h2>
        <div class="experience">
        <table>
          <tr>
            <td>Aug 2024 - May 2025</td>
            <td>Research Intern at <a href="https://airs.cuhk.edu.cn/" target="_blank">AIRS Shenzhen</a>, worked with <a href="https://scholar.google.com/citations?user=nuZZKu4AAAAJ&hl" target="_blank">Prof. Junjie Hu</a>.</td>
          </tr>
        </table>
        </div>

      <!-------------------------------  Preprints -------------------------------------------->
      <!-- <div class="content-container"> -->
      <!-- <h2>Preprints</h2>
        
        <div class="hflex-container" id="paper">
          <img src="images/Arxiv_HAT.jpg">
          <div>
            <p class="title" style="font-size:16">HAT: Hybrid Attention Transformer for Image Restoration</p>
            <p class="authors" style="font-size:14"><span class="author_me">Xiangyu Chen</span>, Xintao Wang, Wnlong Zhang, Xiangtao Kong, Yu Qiao, Jiantao Zhou, Chao Dong</p>
            <a class="pdflink" href="https://arxiv.org/pdf/2309.05239.pdf" target="_blank">Paper</a>
            <a class="codelink" href="https://github.com/XPixelGroup/HAT" target="_blank">Code</a>
          </div>
        </div>

        <div class="hflex-container" id="paper">
          <img src="images/Arxiv_HDRTVNet-plus.jpg">
          <div>
            <p class="title" style="font-size:16">Towards Efficient SDRTV-to-HDRTV by Learning from Image Formation</p>
            <p class="authors" style="font-size:16"><span class="author_me">Xiangyu Chen</span><sup>*</sup>, Zheyuan Li<sup>*</sup>, Zhengwen Zhang, Jimmy S. Ren, Yihao Liu, Jingwen He, Yu Qiao, Jiantao Zhou, Chao Dong</p>
            <a class="pdflink" href="https://arxiv.org/pdf/2309.04084.pdf" target="_blank">Paper</a>
            <a class="codelink" href="https://github.com/xiaom233/HDRTVNet-plus" target="_blank">Code</a>
          </div>
        </div> -->

        <!-- <p>(* equal contribution.)</p> -->
      
    <!-------------------------------  Publications -------------------------------------------->
    <!-- <div class="content-container"> -->
      <h2>Selected Publications</h2>
        <div class="hflex-container" id="paper">
          <img src="images/Arxiv_GenLV.jpg">
          <div>
            <p class="title" style="font-size:16">Learning A Low-Level Vision Generalist via Visual Task Prompt</p>
            <p class="authors" style="font-size:15"><span class="author_me">Xiangyu Chen</span>, Yihao Liu, Yuandong Pu, Wenlong Zhang, Jiantao Zhou, Yu Qiao, Chao Dong</p>
            <p class="venue ICCV">2025</p> <br>
            <a class="pdflink" href="https://arxiv.org/pdf/2408.08601.pdf" target="_blank">Paper</a>
            <a class="codelink" href="https://github.com/chxy95/GenLV" target="_blank">Code</a>
          </div>
        </div>

        <div class="hflex-container" id="paper">
          <img src="images/Arxiv_XRestormer.png">
          <div>
            <p class="title" style="font-size:14">A Comparative Study of Image Restoration Networks for General Backbone Network Design</p>
            <p class="authors" style="font-size:15"><span class="author_me">Xiangyu Chen</span><sup>*</sup>, Zheyuan Li<sup>*</sup>, Yuandong Pu<sup>*</sup>, Yihao Liu, Jiantao Zhou, Yu Qiao, Chao Dong</p>
            <p class="venue ECCV">2024</p> <br>
            <a class="pdflink" href="https://arxiv.org/pdf/2310.11881.pdf" target="_blank">Paper</a>
            <a class="codelink" href="https://github.com/Andrew0613/X-Restormer" target="_blank">Code</a>
          </div>
        </div>

        <div class="hflex-container" id="paper">
          <img src="images/ICML2024_PromptGIP.png">
          <div>
            <p class="title" style="font-size:16">Unifying Image Processing as Visual Prompting Question Answering</p>
            <p class="authors" style="font-size:14">Yihao Liu<sup>*</sup>, <span class="author_me">Xiangyu Chen</span><sup>*</sup>, Xianzheng Ma<sup>*</sup>, Xintao Wang, Jiantao Zhou, Yu Qiao, Chao Dong</p>
            <p class="venue ICML">2024</p> <br>
            <a class="pdflink" href="https://arxiv.org/pdf/2310.10513.pdf" target="_blank">Paper</a>
            <a class="codelink" href="https://github.com/lyh-18/PromptGIP" target="_blank">Code</a>
          </div>
        </div>

        <div class="hflex-container" id="paper">
          <img src="images/ICLR2024_SEAL.jpg">
          <div>
            <p class="title" style="font-size:16">SEAL: A Framework for Systematic Evaluation of Real-World Super-Resolution</p>
            <p class="authors" style="font-size:16">Wenlong Zhang, Xiaohui Li, <span class="author_me">Xiangyu Chen</span>, Yu Qiao, Xiao-Ming Wu, Chao Dong</p>
            <p class="venue ICLR"><span style=color:red;font-weight:bold>Spotlight</span>, 2023</p> <br>
            <a class="pdflink" href="https://openreview.net/forum?id=CGlczSBBSj" target="_blank">Paper</a>
            <a class="codelink" href="https://github.com/XPixelGroup/SEAL" target="_blank">Code</a>
          </div>
        </div>

        <div class="hflex-container" id="paper">
          <img src="images/NeurIPS2023_TGSR.jpg">
          <div>
            <p class="title" style="font-size:16">TGSR: Real-World Image Super-Resolution as Multi-Task Learning</p>
            <p class="authors" style="font-size:16">Wenlong Zhang, Xiaohui Li, Guangyuan Shi, <span class="author_me">Xiangyu Chen</span>, Xiaoyun Zhang, Yu Qiao, Xiao-Ming Wu, Chao Dong</p>
            <p class="venue NeurIPS">2023</p> <br>
            <a class="pdflink" href="https://openreview.net/pdf?id=8SCz56sUGP" target="_blank">Paper</a>
            <a class="codelink" href="https://github.com/XPixelGroup/TGSR" target="_blank">Code</a>
          </div>
        </div>

<!--         <div class="hflex-container" id="paper">
          <img src="images/ICML2023_DeSRA.png">
          <div>
            <p class="title" style="font-size:14">DeSRA: Detect and Delete the Artifacts of GAN-based Real-World Super-Resolution Models</p>
            <p class="authors" style="font-size:15">Liangbin Xie<sup>*</sup>, Xintao Wang<sup>*</sup>, <span class="author_me">Xiangyu Chen</span><sup>*</sup>, Gen Li, Ying Shan, Jiantao Zhou, Chao Dong</p>
            <p class="venue ICML">2023</p> <br>
            <a class="pdflink" href="https://openreview.net/pdf?id=M0bwbIl4Bl" target="_blank">Paper</a>
            <a class="codelink" href="https://github.com/TencentARC/DeSRA" target="_blank">Code</a>
          </div>
        </div> -->

<!--         <div class="hflex-container" id="paper">
          <img src="images/CVPR2023_HAT.png">
          <div>
            <p class="title">HAT: Activating More Pixels in Image Super-Resolution Transformer</p>
            <p class="authors"><span class="author_me">Xiangyu Chen</span>, Xintao Wang, Jiantao Zhou, Yu Qiao, Chao Dong</p>
            <p class="venue CVPR">2023</p> <br>
            <a class="pdflink" href="https://arxiv.org/pdf/2205.04437.pdf" target="_blank">Paper</a>
            <a class="codelink" href="https://github.com/chxy95/HAT" target="_blank">Code</a>
          </div>
        </div> -->
        
        <!--
        <div class="hflex-container" id="paper">
          <img src="images/AAAI2023_LLVE.png">
          <div>
            <p class="title">Low-Light Video Enhancement with Synthetic Event Guidance</p>
            <p class="authors" style="font-size:16">Lin Liu, Junfeng An, Jianzhuang Liu, Shanxin Yuan, <span class="author_me">Xiangyu Chen</span>, Wengang Zhou, Houqiang Li, Yanfeng Wang, Qi Tian</p>
            <p class="venue AAAI">2023 </p> <br>
            <a class="pdflink" href="https://arxiv.org/pdf/2208.11014.pdf" target="_blank">Paper</a>
            <a class="codelink" href="http://home.ustc.edu.cn/~ll0825/project_TAPE.html" target="_blank">Code</a>
          </div>
        </div>

        <div class="hflex-container" id="paper">
          <img src="images/ECCVW2022_VapSR.jpg">
          <div>
            <p class="title" style="font-size:16">VapSR: Efficient Image Super-Resolution using Vast-Receptive-Field Attention</p>
            <p class="authors" style="font-size:14">Lin Zhou<sup>*</sup>, Haoming Cai<sup>*</sup>, Jinjin Gu, Zheyuan Li, Yingqi Liu, <span class="author_me">Xiangyu Chen</span>, Yu Qiao, Chao Dong</p>
            <p class="venue ECCVW">2022 </p> <br>
            <a class="pdflink" href="https://arxiv.org/pdf/2210.05960.pdf" target="_blank">Paper</a>
            <a class="codelink" href="https://github.com/zhoumumu/VapSR" target="_blank">Code</a>
          </div>
        </div>

        <div class="hflex-container" id="paper">
          <img src="images/ECCVW2022_UDCUNet.png">
          <div>
            <p class="title" style="font-size:16">UDC-UNet: Under-Display Camera Image Restoration via U-shape Dynamic Network</p>
            <p class="authors">Xina Liu<sup>*</sup>, Jinfan Hu<sup>*</sup>, <span class="author_me">Xiangyu Chen</span>, Chao Dong</p>
            <p class="venue ECCVW">2022 </p> <br>
            <p class="venue none" style="font-size:15"><span style=color:red;font-weight:bold>2nd place</span>, MIPI 2022 Challenges on Under-display Camera Image Restoration </p> <br>
            <a class="pdflink" href="https://arxiv.org/pdf/2209.01809.pdf" target="_blank">Paper</a>
            <a class="codelink" href="https://github.com/J-FHu/UDCUNet" target="_blank">Code</a>
          </div>
        </div>

        <div class="hflex-container" id="paper">
          <img src="images/TMM2022_CSRNet.jpg">
          <div>
            <p class="title" style="font-size:16">Very lightweight photo retouching network with conditional sequential modulation</p>
            <p class="authors" style="font-size:14">Yihao Liu<sup>*</sup>, Jingwen He<sup>*</sup>, <span class="author_me">Xiangyu Chen</span>, Zhengwen Zhang, Hengyuan Zhao, Chao Dong, Yu Qiao</p>
            <p class="venue tmm">2022</p> <br>
            <a class="pdflink" href="https://arxiv.org/pdf/2104.06279.pdf" target="_blank">Paper</a>
            <a class="codelink" href="https://github.com/lyh-18/CSRNet" target="_blank">Code</a>
          </div>
        </div>
          -->
<!-- 
        <div class="hflex-container" id="paper">
            <img src="images/ECCV2022_TAPE.jpg">
            <div>
              <p class="title">TAPE: Task-Agnostic Prior Embedding for Image Restoration</p>
              <p class="authors" style="font-size:16">Lin Liu, Lingxi Xie, Xiaopeng Zhang, Shanxin Yuan, <span class="author_me">Xiangyu Chen</span>, Wengang Zhou, Houqiang Li, Qi Tian</p>
              <p class="venue ECCV">2022 </p> <br>
              <a class="pdflink" href="http://arxiv.org/pdf/2203.06074.pdf" target="_blank">Paper</a>
              <a class="codelink" href="http://home.ustc.edu.cn/~ll0825/project_TAPE.html" target="_blank">Code</a>
            </div>
        </div>

        <div class="hflex-container" id="paper">
            <img src="images/CVPRW2022_BSRN.jpg">
            <div>
              <p class="title" style="font-size:16">BSRN: Blueprint Separable Residual Network for Efficient Image Super-Resolution</p>
              <p class="authors">Zheyuan Li<sup>*</sup>, Yingqi Liu<sup>*</sup>, <span class="author_me">Xiangyu Chen</span><sup>&#10013</sup>, Haoming Cai, Jinjin Gu, Yu Qiao, Chao Dong</p>
              <p class="venue CVPRW">2022 </p> <br>
              <p class="venue none" style="font-size:15"><span style=color:red;font-weight:bold>Champion</span>, NTIRE 2022 Challenges on Efficient Super-Resolution Model Complexity Track </p> <br>
              <a class="pdflink" href="https://arxiv.org/pdf/2205.05996.pdf" target="_blank">Paper</a>
              <a class="codelink" href="https://github.com/xiaom233/BSRN" target="_blank">Code</a>
            </div>
        </div>

        <div class="hflex-container" id="paper">
          <img src="images/ICCV2021_HDRTVNet.jpg">
          <div>
            <p class="title">A New Journey From SDRTV to HDRTV</p>
            <p class="authors"><span class="author_me">Xiangyu Chen</span><sup>*</sup>, Zhengwen Zhang<sup>*</sup>, Jimmy S. Ren, Lynhoo Tian, Yu Qiao, Chao Dong</p>
            <p class="venue iccv">2021</p> <br>
            <a class="pdflink"><a href="https://arxiv.org/pdf/2108.07978.pdf" target="_blank">Paper</a>
            <a class="codelink" href="https://github.com/chxy95/HDRTVNet" target="_blank">Code</a>
          </div>
        </div>

        <div class="hflex-container" id="paper">
            <img src="images/CVPRW2021_HDRUNet.jpg">
            <div>
                <p class="title" style="font-size:16">HDRUNet: Single Image HDR Reconstruction with Denoising and Dequantization</p>
                <p class="authors"><span class="author_me">Xiangyu Chen</span>, Yihao Liu, Zhengwen Zhang, Yu Qiao, Chao Dong</p>
                <p class="venue cvprw">2021</p> <br>
                <p class="venue none" style="font-size:15"><span style=color:red;font-weight:bold>2nd place</span>, NTIRE 2021 Challenges on High Dynamic Range Imaging Single Frame Track </p> <br>
                <a class="pdflink" href="https://arxiv.org/pdf/2105.13084.pdf">Paper</a>
                <a class="codelink" href="https://github.com/chxy95/HDRUNet" target="_blank">Code</a>
            </div>
        </div>
 -->
        <p>(* equal contribution, &#10013 corresponding author.)</p>
        <!-- </div> -->

    <!-------------------------------  My Interns -------------------------------------------->
<!--       <h2>My Students & Interns</h2>
        <div class="student&intern">
        <table>
          <tr>
            <td><b>Name</b></td>
            <td><b>Position</b></td>
            <td><b>Duration</b></td>
            <td><b>Background</b></td>
            <td><b>Next Station</b></td>
          </tr>
          <tr>
            <td><a href="https://github.com/Xiaolong-RRL" target="_blank">Ruilong Ren</a></td>
            <td>Research Intern</td>
            <td>2024.10 - 2025.6</td>
            <td>MSc student at Peking University</td>
            <td>Huawei</td>
          </tr>
          <tr>
            <td>Jiaqi Yan</td>
            <td>Research Intern</td>
            <td>2024.10 - Now</td>
            <td>MSc student at Nanjing University</td>
            <td> ---- </td>
          </tr>
          <tr>
            <td><a href="https://daviswang0.github.io" target="_blank">Ling Wang</a></td>
            <td>Research Intern</td>
            <td>2024.12 - Now</td>
            <td>MSc student at HKUST (GZ)</td>
            <td> ---- </td>
          </tr>
          <tr>
            <td><a href="https://scholar.google.com/citations?user=VHymY7EAAAAJ&hl=en" target="_blank">Jingren Liu</a></td>
            <td>Research Intern</td>
            <td>2025.01 - Now</td>
            <td>PhD student at Tianjin University</td>
            <td> ---- </td>
          </tr>
          <tr>
            <td><a href="https://scholar.google.com/citations?user=vXPIEjsAAAAJ&hl=en" target="_blank">Shuning Xu</a></td>
            <td>Research Intern</td>
            <td>2025.01 - Now</td>
            <td>PhD student at University of Macau</td>
            <td> ---- </td>
          </tr>
          <tr>
            <td>Yiheng Wang</td>
            <td>Engineering Intern</td>
            <td>2025.03 - Now</td>
            <td>BSc student at Tongji University</td>
            <td> Duke University</td>
          </tr>
          <tr>
            <td><a href="https://scholar.google.com/citations?view_op=list_works&hl=en&hl=en&user=8fma3awAAAAJ" target="_blank">Yun Wang</a></td>
            <td>Research Intern</td>
            <td>2025.05 - Now</td>
            <td>PhD student at City University of Hong Kong</td>
            <td> ---- </td>
          </tr>
          <tr>
            <td>Long Zhang</td>
            <td>Research Intern</td>
            <td>2025.05 - Now</td>
            <td>MSc student at USTC</td>
            <td> ---- </td>
          </tr>
        </table>
        </div> -->

    <!-------------------------------  Other information -------------------------------------------->
      <h2>Professional Activities</h2>
			<ul>
        <li><b>Conference Reviewer</b>:
          <ul>
            <li>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</li>
            <li>International Conference on Computer Vision (ICCV)</li>
            <li>European Conference on Computer Vision (ECCV)</li>
            <li>Neural Information Processing Systems (NeurIPS)</li>
            <li>AAAI Conference on Artificial Intelligence (AAAI)</li>
          </ul>
        </li>
        <br>
				<li><b>Journal Reviewer</b>:
          <ul>
            <li>IEEE Transactions on Image Processing (TIP)</li>
            <li>IEEE Transactions on Multimedia (TMM)</li>
            <li>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</li>
          </ul>
			</ul>

      <!-- <h2>Awards</h2>
			<ul>
        <li>Hong Kong PhD Fellowship, HKU, 2015 - 2018</li>
				<li>National Scholarship, HUST, 2011 - 2012</li>
			</ul> -->

		  <!-- <div class="content-container"> -->
			<!-- <h2>Teaching</h2>
			<ul>
        <li>[2017/18 2nd semester]: COMP3317 Computer Vision&nbsp;~ Teaching Assistant</li>
				<li>[2015/16 2nd semester]: COMP2396 Object-Oriented Programming and Java&nbsp;~ Teaching Assistant</li>
				<li>[2016/17 1st semester]: COMP2396 Object-Oriented Programming and Java&nbsp;~ Teaching Assistant</li>
			</ul>

			<h2>Friend Links</h2>
			<table width="800">
				<tr>
					<td>
					    <ul>
					       	<li><a href="http://xiaolongzhu.org" target="_blank">Xiaolong Zhu</a></li>
					       	<li><a href="http://www.xtan.org" target="_blank">Xiao Tan</a></li>
					       	<li><a href="http://www.hankai.org" target="_blank">Kai Han</a></li>
					       	<li><a href="http://www.cs.hku.hk/~wliu" target="_blank">Wei Liu</a></li>
					       	<li><a href="https://guanyingc.github.io/" target="_blank">Guanying Chen</a></li>
					       	<li><a href="https://zfchenunique.github.io/" target="_blank">Zhenfang Chen</a></li>
					       	<li><a href="https://csxmli2016.github.io//" target="_blank">Xiaoming Li</a></li>
						</ul>
					</td>
					<td>
						<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?u=8L5p&d=oIqbE94OTEQX6b36vXK28iFbZ1SwGCJXKVMwX5205rQ"></script>
					</td>
				</tr>
			</table> -->
		<!-- </div> -->
	
    <div style="max-width: 50%; margin: 0 auto">
      <script type='text/javascript' id='clustrmaps' 
      src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=500&t=tt&d=LevnxGWQ6H9GHTP5_XvQ4H-SBGlKZIbxVUETejjcwgM&co=2d78ad&cmo=3acc3a&cmn=ff5353&ct=ffffff'>
      </script>
    </div>
  </div>

</body>
</html>
